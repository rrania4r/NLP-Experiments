{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code experimenting with creating a corpus, and using TFIDF, LSA, LDA : modelling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  Human machine interface for lab abc computer a...\n",
      "1  A survey of user opinion of computer system re...\n",
      "2          The EPS user interface management system,\n",
      "3  System and human system engineering testing of...\n",
      "4  Relation of user perceived response time to er...\n"
     ]
    }
   ],
   "source": [
    "# First steps: get the necessary packages, and load the text:\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import regexp_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "\n",
    "texts_list = pd.read_csv(\"NLPexample.txt\", header = None, names = [\"Text\"], delimiter = \"\\t\")\n",
    "\n",
    "# Alternatives:\n",
    "#texts_list = pd.read_csv(\"NLPexample.txt\", header = None, names = [\"Text\"], usecols = [0])\n",
    "# OR, if the file doesn't contain commas:\n",
    "# texts_list = pd.read_csv(\"NLPexample2.txt\", header = None, names = [\"Text\"])\n",
    "\n",
    "\n",
    "# what does it look like?\n",
    "print(texts_list.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for creating Ngrams\n",
    "\n",
    "def sum_string(text, j, N):\n",
    "    \"\"\"\n",
    "    Helper function for creating N-grams, which adjoins the next word in the text to\n",
    "    the existing Ngram via \"_\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if N > len(text) - j:\n",
    "        raise ValueError(\"N is too long for the text\")\n",
    "    if N == 1:\n",
    "        return text[j]\n",
    "    return text[j] + \"_\" + sum_string(text, j+1, N - 1)\n",
    "\n",
    "\n",
    "def join_tokens(doc, N = 2):\n",
    "    \"\"\"\n",
    "    Convert a list of tokens into N-gram tokens\n",
    "    the N-grams returned are the tokens\n",
    "    \"\"\"\n",
    "    #construct ngrams from tokens\n",
    "    if len(doc) > N - 1:\n",
    "        for i in range(0,len(doc)- N + 1):\n",
    "            yield sum_string(doc, i, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to lower case\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lower_tokens = [t.lower() for t in texts_list.Text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human machine interface for lab abc computer applications,',\n",
       " 'a survey of user opinion of computer system response time,',\n",
       " 'the eps user interface management system,',\n",
       " 'system and human system engineering testing of eps,',\n",
       " 'relation of user perceived response time to error measurement,',\n",
       " 'the generation of random binary unordered trees,',\n",
       " 'the intersection graph of paths in trees,',\n",
       " 'graph minors iv widths of trees and well quasi ordering,',\n",
       " 'graph minors a survey']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Gensim corpus to investigate word frequencies\n",
    "# Creating a gensim corpus\n",
    "\n",
    "\n",
    "tokenized_docs = [regexp_tokenize(doc, \"\\w+\") for doc in lower_tokens]\n",
    "\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words_add = [\"consolidated\", \"detail\", \"details\", \"summary\", \"summaries\"]\n",
    "[stop_words.append(w) for w in stop_words_add]\n",
    "\n",
    "# Tokenized_docs is a list of list, so it needs a \"double\" generator\n",
    "cleaned_text = [[t for t in doc if t not in stop_words] for doc in tokenized_docs] \n",
    "\n",
    "\n",
    "cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "Create a function that takes as input:\n",
    "* cleaned text\n",
    "* n for ngram\n",
    "* dimension of reduced space (NumTopics)\n",
    "* how many words to include in topic Words\n",
    "\n",
    "And produces as output:\n",
    "DataFrame with Frequency, topicID, and topicWords.  Topics built by LSA\n",
    "\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-12 16:18:58,097 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-04-12 16:18:58,098 : INFO : built Dictionary(35 unique tokens: ['abc', 'applications', 'computer', 'human', 'interface']...) from 9 documents (total 52 corpus positions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(2, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(4, 1), (10, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(3, 1), (10, 2), (13, 1), (15, 1), (16, 1)],\n",
       " [(8, 1), (11, 1), (12, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(21, 1), (22, 1), (23, 1), (24, 1), (25, 1)],\n",
       " [(24, 1), (26, 1), (27, 1), (28, 1)],\n",
       " [(24, 1), (26, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)],\n",
       " [(9, 1), (26, 1), (30, 1)]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1\n",
    "# Create the Ngrams\n",
    "Ngrams_text = [list(join_tokens(doc, N)) for doc in cleaned_text]\n",
    "\n",
    "# Create the gensim dictionary and corpus\n",
    "# dictionary: creates a mapping between tokens in the Ngrams_text, and an integer id\n",
    "# corpus:  uses the integer id to count number of occurrences of tokens in each document\n",
    "dictionary = Dictionary(Ngrams_text)\n",
    "    \n",
    "corpus = [dictionary.doc2bow(doc) for doc in Ngrams_text]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 4),\n",
       " (12, 3),\n",
       " (24, 3),\n",
       " (26, 3),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (8, 2),\n",
       " (9, 2),\n",
       " (11, 2),\n",
       " (13, 2),\n",
       " (30, 2),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (25, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the defaultdict: total_word_count (i.e. initialize an empty dictionary)\n",
    "total_word_count = defaultdict(int)\n",
    "\n",
    "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
    "    total_word_count[word_id] += word_count\n",
    "\n",
    "# Create a sorted list from the defaultdict, which counts number of occurrences of a word over all documents\n",
    "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True)\n",
    "\n",
    "    \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sorted_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an TFIDF Model with the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-12 16:53:45,699 : INFO : collecting document frequencies\n",
      "2019-04-12 16:53:45,700 : INFO : PROGRESS: processing document #0\n",
      "2019-04-12 16:53:45,700 : INFO : calculating IDF weights for 9 documents and 34 features (51 matrix non-zeros)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4301019571350565), (1, 0.4301019571350565), (2, 0.2944198962221451), (3, 0.2944198962221451), (4, 0.2944198962221451), (5, 0.4301019571350565), (6, 0.4301019571350565)]\n",
      "[(2, 0.3726494271826947), (7, 0.5443832091958983), (8, 0.3726494271826947), (9, 0.3726494271826947), (10, 0.27219160459794917), (11, 0.3726494271826947), (12, 0.27219160459794917)]\n",
      "[(4, 0.438482464916089), (10, 0.32027755044706185), (12, 0.32027755044706185), (13, 0.438482464916089), (14, 0.6405551008941237)]\n",
      "[(3, 0.3449874408519962), (10, 0.5039733231394895), (13, 0.3449874408519962), (15, 0.5039733231394895), (16, 0.5039733231394895)]\n",
      "[(8, 0.30055933182961736), (11, 0.30055933182961736), (12, 0.21953536176370683), (17, 0.43907072352741366), (18, 0.43907072352741366), (19, 0.43907072352741366), (20, 0.43907072352741366)]\n",
      "[(21, 0.48507125007266594), (22, 0.48507125007266594), (23, 0.48507125007266594), (24, 0.24253562503633297), (25, 0.48507125007266594)]\n",
      "[(24, 0.31622776601683794), (26, 0.31622776601683794), (27, 0.6324555320336759), (28, 0.6324555320336759)]\n",
      "[(24, 0.20466057569885868), (26, 0.20466057569885868), (29, 0.40932115139771735), (30, 0.2801947048062438), (31, 0.40932115139771735), (32, 0.40932115139771735), (33, 0.40932115139771735), (34, 0.40932115139771735)]\n",
      "[(9, 0.6282580468670046), (26, 0.45889394536615247), (30, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus) \n",
    "\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "     print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an LSA Model with the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-12 16:24:24,422 : INFO : using serial LSI version on this node\n",
      "2019-04-12 16:24:24,423 : INFO : updating model with new documents\n",
      "2019-04-12 16:24:24,423 : INFO : preparing a new chunk of documents\n",
      "2019-04-12 16:24:24,424 : INFO : using 100 extra samples and 2 power iterations\n",
      "2019-04-12 16:24:24,424 : INFO : 1st phase: constructing (35, 200) action matrix\n",
      "2019-04-12 16:24:24,425 : INFO : orthonormalizing (35, 200) action matrix\n",
      "2019-04-12 16:24:24,427 : INFO : 2nd phase: running dense svd on (35, 9) matrix\n",
      "2019-04-12 16:24:24,428 : INFO : computing the final decomposition\n",
      "2019-04-12 16:24:24,428 : INFO : keeping 9 factors (discarding 0.000% of energy spectrum)\n",
      "2019-04-12 16:24:24,429 : INFO : processed documents up to #9\n",
      "2019-04-12 16:24:24,430 : INFO : topic #0(3.594): 0.579*\"system\" + 0.376*\"user\" + 0.270*\"eps\" + 0.257*\"time\" + 0.257*\"response\" + 0.230*\"computer\" + 0.224*\"human\" + 0.191*\"interface\" + 0.176*\"survey\" + 0.157*\"opinion\"\n",
      "2019-04-12 16:24:24,430 : INFO : topic #1(3.148): -0.480*\"graph\" + -0.464*\"trees\" + -0.361*\"minors\" + -0.266*\"well\" + -0.266*\"ordering\" + -0.266*\"widths\" + -0.266*\"iv\" + -0.266*\"quasi\" + -0.119*\"paths\" + -0.119*\"intersection\"\n",
      "2019-04-12 16:24:24,431 : INFO : topic #2(2.868): 0.359*\"response\" + 0.359*\"time\" + -0.313*\"system\" + 0.301*\"user\" + -0.290*\"human\" + -0.244*\"eps\" + 0.241*\"measurement\" + 0.241*\"perceived\" + 0.241*\"error\" + 0.241*\"relation\"\n",
      "2019-04-12 16:24:24,431 : INFO : topic #3(2.543): 0.371*\"computer\" + 0.357*\"machine\" + 0.357*\"abc\" + 0.357*\"applications\" + 0.357*\"lab\" + -0.347*\"system\" + 0.309*\"interface\" + -0.204*\"eps\" + 0.201*\"human\" + -0.156*\"engineering\"\n",
      "2019-04-12 16:24:24,432 : INFO : topic #4(2.215): -0.412*\"binary\" + -0.412*\"generation\" + -0.412*\"unordered\" + -0.412*\"random\" + -0.373*\"trees\" + 0.221*\"minors\" + 0.141*\"graph\" + 0.135*\"survey\" + 0.119*\"widths\" + 0.119*\"well\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/1-gram_model_100.lsi\n"
     ]
    }
   ],
   "source": [
    "NumTopics = 100\n",
    "# initialize an LSI transformation\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=NumTopics) \n",
    "corpus_lsi = lsi[corpus]\n",
    "    \n",
    "# Model persistency is achieved with the save() and load() functions:\n",
    "ModelName = \"Models/\" + str(N) + \"-gram_model_\" + str(NumTopics) + \".lsi\"\n",
    "print(ModelName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-12 16:27:34,098 : INFO : saving Projection object under Models/1-gram_model_100.lsi.projection, separately None\n",
      "2019-04-12 16:27:34,099 : INFO : saved Models/1-gram_model_100.lsi.projection\n",
      "2019-04-12 16:27:34,100 : INFO : saving LsiModel object under Models/1-gram_model_100.lsi, separately None\n",
      "2019-04-12 16:27:34,101 : INFO : not storing attribute projection\n",
      "2019-04-12 16:27:34,101 : INFO : not storing attribute dispatcher\n",
      "2019-04-12 16:27:34,102 : INFO : saved Models/1-gram_model_100.lsi\n"
     ]
    }
   ],
   "source": [
    "lsi.save(ModelName) # same for tfidf, lda, ...\n",
    "\n",
    "# And, to load a previously saved model:\n",
    "# lsi = models.LsiModel.load(ModelName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-12 16:55:52,372 : INFO : using serial LSI version on this node\n",
      "2019-04-12 16:55:52,373 : INFO : updating model with new documents\n",
      "2019-04-12 16:55:52,374 : INFO : preparing a new chunk of documents\n",
      "2019-04-12 16:55:52,374 : INFO : using 100 extra samples and 2 power iterations\n",
      "2019-04-12 16:55:52,375 : INFO : 1st phase: constructing (35, 200) action matrix\n",
      "2019-04-12 16:55:52,375 : INFO : orthonormalizing (35, 200) action matrix\n",
      "2019-04-12 16:55:52,377 : INFO : 2nd phase: running dense svd on (35, 9) matrix\n",
      "2019-04-12 16:55:52,378 : INFO : computing the final decomposition\n",
      "2019-04-12 16:55:52,378 : INFO : keeping 9 factors (discarding 0.000% of energy spectrum)\n",
      "2019-04-12 16:55:52,379 : INFO : processed documents up to #9\n",
      "2019-04-12 16:55:52,379 : INFO : topic #0(1.266): 0.400*\"system\" + 0.318*\"survey\" + 0.290*\"user\" + 0.274*\"eps\" + 0.236*\"management\" + 0.236*\"opinion\" + 0.235*\"response\" + 0.235*\"time\" + 0.224*\"interface\" + 0.224*\"computer\"\n",
      "2019-04-12 16:55:52,380 : INFO : topic #1(1.177): 0.421*\"minors\" + 0.420*\"graph\" + 0.293*\"survey\" + 0.239*\"trees\" + 0.226*\"paths\" + 0.226*\"intersection\" + -0.204*\"system\" + -0.196*\"eps\" + 0.189*\"ordering\" + 0.189*\"widths\"\n",
      "2019-04-12 16:55:52,380 : INFO : topic #2(1.071): -0.318*\"response\" + -0.318*\"time\" + -0.261*\"measurement\" + -0.261*\"relation\" + -0.261*\"error\" + -0.261*\"perceived\" + 0.248*\"eps\" + -0.203*\"opinion\" + 0.195*\"human\" + 0.190*\"engineering\"\n",
      "2019-04-12 16:55:52,381 : INFO : topic #3(1.007): 0.416*\"generation\" + 0.416*\"unordered\" + 0.416*\"binary\" + 0.416*\"random\" + 0.256*\"trees\" + -0.225*\"minors\" + -0.177*\"survey\" + 0.161*\"paths\" + 0.161*\"intersection\" + 0.119*\"relation\"\n",
      "2019-04-12 16:55:52,381 : INFO : topic #4(0.966): -0.398*\"lab\" + -0.398*\"machine\" + -0.398*\"abc\" + -0.398*\"applications\" + -0.301*\"computer\" + 0.242*\"system\" + 0.237*\"eps\" + 0.180*\"testing\" + 0.180*\"engineering\" + 0.166*\"management\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/1-gram_tfidf_model_100.lsi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we could also initialize an LSI transformation on the TFIDF weighted corpus:\n",
    "lsi_t = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=NumTopics) \n",
    "corpus_lsi_t = lsi_t[corpus_tfidf]\n",
    "    \n",
    "# Model persistency is achieved with the save() and load() functions:\n",
    "ModelName = \"Models/\" + str(N) + \"-gram_tfidf_model_\" + str(NumTopics) + \".lsi\"\n",
    "print(ModelName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/1-gram_LSA_model_100.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>topicID</th>\n",
       "      <th>topicWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[(system, 0.578819723500462), (user, 0.3761191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[(computer, 0.3707031576945169), (machine, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[(survey, -0.5119821128613758), (opinion, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[(graph, -0.48022933420716), (trees, -0.463778...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[(response, 0.35877026141443874), (time, 0.358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>[(minors, -0.47153189957653346), (survey, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[(intersection, -0.4962393745482648), (paths, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[(management, 0.49502605579427394), (interface...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[(binary, -0.41214564245205937), (generation, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  topicID                                         topicWORDS\n",
       "0  8        0  [(system, 0.578819723500462), (user, 0.3761191...\n",
       "3  5        3  [(computer, 0.3707031576945169), (machine, 0.3...\n",
       "5  5        5  [(survey, -0.5119821128613758), (opinion, -0.3...\n",
       "1  3        1  [(graph, -0.48022933420716), (trees, -0.463778...\n",
       "2  3        2  [(response, 0.35877026141443874), (time, 0.358...\n",
       "8  3        8  [(minors, -0.47153189957653346), (survey, -0.3...\n",
       "6  3        6  [(intersection, -0.4962393745482648), (paths, ...\n",
       "7  3        7  [(management, 0.49502605579427394), (interface...\n",
       "4  3        4  [(binary, -0.41214564245205937), (generation, ..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumWords = 5\n",
    "# Create a list with the 4 most important topics per document\n",
    "sorted_corpus_lsi = [sorted(doc, key = lambda x: x[1], reverse = True)[:4] for doc in corpus_lsi]\n",
    "\n",
    "# Count the frequency of occurrence of each LSA topic\n",
    "topics_count  = defaultdict(int)\n",
    "for n in sorted_corpus_lsi:\n",
    "    for t in n:\n",
    "        topics_count[t[0]] += 1\n",
    "     \n",
    "# To make computation easier, we will turn everything into a dataframe, and sort it on frequency:\n",
    "df = pd.DataFrame.from_dict(topics_count, orient='index', dtype=None)\n",
    "df_sorted = df.sort_values([0], ascending=[False])\n",
    "\n",
    "df_sorted[\"topicID\"] = df_sorted.index\n",
    "    \n",
    "# Add a column with the top NumWords words belonging to each topicID:\n",
    "df_sorted[\"topicWORDS\"] = df_sorted[\"topicID\"].apply(lsi.show_topic, topn = NumWords)\n",
    "    \n",
    "# Lets save the Data Frame:\n",
    "dfName = \"Models/\" + str(N) + \"-gram_LSA_model_\" + str(NumTopics) + \".pkl\"\n",
    "print(dfName)\n",
    "\n",
    "df_sorted.to_pickle(dfName)    #to save the dataframe df_sorted to a pickle file, .pkl \n",
    "# df_sorted = pd.read_pickle(dfName) #to load the .pkl file back to the dataframe df_sorted\n",
    "    \n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an LDA Model with the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-12 16:33:48,105 : INFO : using symmetric alpha at 0.01\n",
      "2019-04-12 16:33:48,106 : INFO : using symmetric eta at 0.01\n",
      "2019-04-12 16:33:48,107 : INFO : using serial LDA version on this node\n",
      "2019-04-12 16:33:48,108 : INFO : running online (single-pass) LDA training, 100 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-04-12 16:33:48,108 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-04-12 16:33:48,113 : INFO : -214.317 per-word bound, 32800323523486367269542980686831505104316505682689996944314466304.0 perplexity estimate based on a held-out corpus of 9 documents with 52 words\n",
      "2019-04-12 16:33:48,114 : INFO : PROGRESS: pass 0, at document #9/9\n",
      "2019-04-12 16:33:48,118 : INFO : topic #77 (0.010): 0.029*\"graph\" + 0.029*\"intersection\" + 0.029*\"relation\" + 0.029*\"binary\" + 0.029*\"generation\" + 0.029*\"random\" + 0.029*\"trees\" + 0.029*\"unordered\" + 0.029*\"measurement\" + 0.029*\"minors\"\n",
      "2019-04-12 16:33:48,118 : INFO : topic #14 (0.010): 0.029*\"graph\" + 0.029*\"intersection\" + 0.029*\"relation\" + 0.029*\"binary\" + 0.029*\"generation\" + 0.029*\"random\" + 0.029*\"trees\" + 0.029*\"unordered\" + 0.029*\"measurement\" + 0.029*\"minors\"\n",
      "2019-04-12 16:33:48,119 : INFO : topic #75 (0.010): 0.029*\"graph\" + 0.029*\"intersection\" + 0.029*\"relation\" + 0.029*\"binary\" + 0.029*\"generation\" + 0.029*\"random\" + 0.029*\"trees\" + 0.029*\"unordered\" + 0.029*\"measurement\" + 0.029*\"minors\"\n",
      "2019-04-12 16:33:48,119 : INFO : topic #97 (0.010): 0.029*\"graph\" + 0.029*\"intersection\" + 0.029*\"relation\" + 0.029*\"binary\" + 0.029*\"generation\" + 0.029*\"random\" + 0.029*\"trees\" + 0.029*\"unordered\" + 0.029*\"measurement\" + 0.029*\"minors\"\n",
      "2019-04-12 16:33:48,119 : INFO : topic #29 (0.010): 0.029*\"graph\" + 0.029*\"intersection\" + 0.029*\"relation\" + 0.029*\"binary\" + 0.029*\"generation\" + 0.029*\"random\" + 0.029*\"trees\" + 0.029*\"unordered\" + 0.029*\"measurement\" + 0.029*\"minors\"\n",
      "2019-04-12 16:33:48,120 : INFO : topic diff=92.517738, rho=1.000000\n",
      "2019-04-12 16:33:48,120 : INFO : saving LdaState object under Models/1-gram_model_100.lda.state, separately None\n",
      "2019-04-12 16:33:48,121 : INFO : saved Models/1-gram_model_100.lda.state\n",
      "2019-04-12 16:33:48,121 : INFO : saving LdaModel object under Models/1-gram_model_100.lda, separately ['expElogbeta', 'sstats']\n",
      "2019-04-12 16:33:48,122 : INFO : storing np array 'expElogbeta' to Models/1-gram_model_100.lda.expElogbeta.npy\n",
      "2019-04-12 16:33:48,123 : INFO : not storing attribute id2word\n",
      "2019-04-12 16:33:48,123 : INFO : not storing attribute state\n",
      "2019-04-12 16:33:48,123 : INFO : not storing attribute dispatcher\n",
      "2019-04-12 16:33:48,124 : INFO : saved Models/1-gram_model_100.lda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/1-gram_model_100.lda\n"
     ]
    }
   ],
   "source": [
    "NumTopics = 100\n",
    "# initialize an LSI transformation\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=NumTopics) \n",
    "corpus_lda = lda[corpus]\n",
    "    \n",
    "# Model persistency is achieved with the save() and load() functions:\n",
    "ModelName = \"Models/\" + str(N) + \"-gram_model_\" + str(NumTopics) + \".lda\"\n",
    "print(ModelName)\n",
    "\n",
    "lda.save(ModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/1-gram_LDA_model_100.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>topicID</th>\n",
       "      <th>topicWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>[(time, 0.13741508), (opinion, 0.13741504), (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[(trees, 0.120958194), (ordering, 0.12095818),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[(interface, 0.13741532), (human, 0.13741527),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>[(eps, 0.18878533), (system, 0.18878524), (man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[(system, 0.31653577), (testing, 0.15905508), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>[(time, 0.13741516), (relation, 0.13741508), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>[(random, 0.18878518), (trees, 0.18878509), (b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>[(trees, 0.23218404), (graph, 0.23218378), (in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  topicID                                         topicWORDS\n",
       "84  2       84  [(time, 0.13741508), (opinion, 0.13741504), (c...\n",
       "4   2        4  [(trees, 0.120958194), (ordering, 0.12095818),...\n",
       "17  1       17  [(interface, 0.13741532), (human, 0.13741527),...\n",
       "23  1       23  [(eps, 0.18878533), (system, 0.18878524), (man...\n",
       "7   1        7  [(system, 0.31653577), (testing, 0.15905508), ...\n",
       "28  1       28  [(time, 0.13741516), (relation, 0.13741508), (...\n",
       "27  1       27  [(random, 0.18878518), (trees, 0.18878509), (b...\n",
       "96  1       96  [(trees, 0.23218404), (graph, 0.23218378), (in..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumWords = 5\n",
    "# Create a list with the 4 most important topics per document\n",
    "sorted_corpus_lda = [sorted(doc, key = lambda x: x[1], reverse = True)[:4] for doc in corpus_lda]\n",
    "\n",
    "# Count the frequency of occurrence of each LSA topic\n",
    "topics_count  = defaultdict(int)\n",
    "for n in sorted_corpus_lda:\n",
    "    for t in n:\n",
    "        topics_count[t[0]] += 1\n",
    "     \n",
    "# To make computation easier, we will turn everything into a dataframe, and sort it on frequency:\n",
    "df = pd.DataFrame.from_dict(topics_count, orient='index', dtype=None)\n",
    "df_sorted = df.sort_values([0], ascending=[False])\n",
    "\n",
    "df_sorted[\"topicID\"] = df_sorted.index\n",
    "    \n",
    "# Add a column with the top NumWords words belonging to each topicID:\n",
    "df_sorted[\"topicWORDS\"] = df_sorted[\"topicID\"].apply(lda.show_topic, topn = NumWords)\n",
    "    \n",
    "# Lets save the Data Frame:\n",
    "dfName = \"Models/\" + str(N) + \"-gram_LDA_model_\" + str(NumTopics) + \".pkl\"\n",
    "print(dfName)\n",
    "\n",
    "df_sorted.to_pickle(dfName)    #to save the dataframe df_sorted to a pickle file, .pkl \n",
    "# df_sorted = pd.read_pickle(dfName) #to load the .pkl file back to the dataframe df_sorted\n",
    "    \n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
